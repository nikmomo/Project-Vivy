{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Use: *Transformer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Environement Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Niko\\anaconda3\\envs\\ProjectVivy\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Niko\\anaconda3\\envs\\ProjectVivy\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LayerNormalization, Dropout, MultiHeadAttention, TimeDistributed, Masking\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import pad_sequences, to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "import ast\n",
    "import gc\n",
    "\n",
    "file_path = 'normalized_output.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PositionalEncoding(tf.keras.layers.Layer):\n",
    "#     def __init__(self, position, d_model):\n",
    "#         super(PositionalEncoding, self).__init__()\n",
    "#         self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "#     def get_angles(self, position, i, d_model):\n",
    "#         # Ensure all operations are done using float32 data type\n",
    "#         position = tf.cast(position, dtype=tf.float32)\n",
    "#         i = tf.cast(i, dtype=tf.float32)\n",
    "#         d_model = tf.cast(d_model, dtype=tf.float32)\n",
    "#         angle_rates = 1 / tf.pow(10000, (2 * (i // 2)) / d_model)\n",
    "#         return position * angle_rates\n",
    "\n",
    "#     def positional_encoding(self, position, d_model):\n",
    "#         angle_rads = self.get_angles(\n",
    "#             position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "#             i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "#             d_model=d_model)\n",
    "#         # apply sin to even indices in the array; 2i\n",
    "#         sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "#         # apply cos to odd indices in the array; 2i+1\n",
    "#         cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "#         pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "#         pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "#         return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         # Ensure inputs are float32 before adding positional encoding\n",
    "#         inputs = tf.cast(inputs, tf.float32)\n",
    "#         return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert string representations of lists to actual lists\n",
    "data['ph_seq_encoded'] = data['ph_seq_encoded'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "data['ph_dur'] = data['ph_dur'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "data['f0_seq'] = data['f0_seq'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else x)  # Handle NaN for f0_seq\n",
    "data['note_seq_encoded'] = data['note_seq_encoded'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Normalize the float arrays\n",
    "scaler_ph_dur = MinMaxScaler(feature_range=(0, 1))\n",
    "# Normalize ph_dur assuming they are already in the correct format\n",
    "data['ph_dur'] = [scaler_ph_dur.fit_transform(np.array(seq).reshape(-1, 1)).flatten() for seq in data['ph_dur']]\n",
    "\n",
    "# Only normalize f0_seq if it's not NaN\n",
    "scaler_f0_seq = MinMaxScaler(feature_range=(0, 1))\n",
    "data['f0_seq'] = [scaler_f0_seq.fit_transform(np.array(seq).reshape(-1, 1)).flatten() if seq is not np.nan else np.nan for seq in data['f0_seq']]\n",
    "\n",
    "# Find the maximum sequence length across all sequence columns\n",
    "max_sequence_length = max(\n",
    "    max(data['ph_seq_encoded'].apply(len)),\n",
    "    max(data['ph_dur'].apply(len)),\n",
    "    max([len(seq) for seq in data['f0_seq'] if seq is not np.nan]),  # Only consider non-NaN sequences\n",
    "    max(data['note_seq_encoded'].apply(len))\n",
    ")\n",
    "\n",
    "# Pad the sequences\n",
    "data['ph_seq_encoded'] = pad_sequences(data['ph_seq_encoded'], maxlen=max_sequence_length, padding='post').tolist()\n",
    "data['ph_dur'] = pad_sequences(data['ph_dur'], maxlen=max_sequence_length, padding='post', dtype='float').tolist()\n",
    "data['f0_seq'] = [pad_sequences([seq], maxlen=max_sequence_length, padding='post', dtype='float').flatten() if seq is not np.nan else np.full(max_sequence_length, np.nan) for seq in data['f0_seq']]\n",
    "data['note_seq_encoded'] = pad_sequences(data['note_seq_encoded'], maxlen=max_sequence_length, padding='post').tolist()\n",
    "\n",
    "# Flatten all sequences into a single list\n",
    "all_ph_seq = [item for sublist in data['ph_seq_encoded'] for item in sublist]\n",
    "\n",
    "# Convert to numpy array and reshape to be 2D\n",
    "all_ph_seq_array = np.array(all_ph_seq).reshape(-1, 1)\n",
    "del all_ph_seq\n",
    "\n",
    "# Determine the number of categories for notes\n",
    "num_note_categories = max(data['note_seq_encoded'].apply(max)) + 1  # Assuming the sequences are zero-indexed\n",
    "\n",
    "# Determine the number of unique phonemes and notes for embeddings\n",
    "num_phonemes = len(np.unique(all_ph_seq_array))\n",
    "num_notes = num_note_categories  # from your previous code\n",
    "\n",
    "# Prepare the dataset for the transformer\n",
    "X_phonemes = np.array(data['ph_seq_encoded'].tolist())\n",
    "y_ph_dur = np.array(data['ph_dur'].tolist())\n",
    "y_notes = np.array(data['note_seq_encoded'].tolist())\n",
    "y_f0_seq = np.array(data['f0_seq'].tolist())\n",
    "\n",
    "# Ensure that all arrays have three dimensions\n",
    "y_ph_dur = y_ph_dur[..., np.newaxis]  # shape (num_sequences, sequence_length, 1)\n",
    "\n",
    "# Split into inputs and targets\n",
    "X_train, X_test, y_ph_dur_train, y_ph_dur_test, y_notes_train, y_notes_test, y_f0_seq_train, y_f0_seq_test = train_test_split(\n",
    "    X_phonemes, y_ph_dur, y_notes, y_f0_seq, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert f0_seq to a masked array for handling NaN values in the training data\n",
    "mask_value = -999  # This should be a value that doesn't naturally occur in the dataset\n",
    "y_f0_seq_train_masked = np.array([np.where(np.isnan(seq), mask_value, seq) for seq in y_f0_seq_train])\n",
    "y_f0_seq_test_masked = np.array([np.where(np.isnan(seq), mask_value, seq) for seq in y_f0_seq_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free some memory here\n",
    "# del all_ph_seq_array\n",
    "# del all_ph_seq\n",
    "# del data\n",
    "# del y_ph_dur\n",
    "# gc.collect()\n",
    "\n",
    "# y_ph_dur_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/101 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Niko\\Documents\\GitHub\\Song-Generation-Model-with-Vocal-Project-Vivy\\model_training_Transformer_self_supervise.ipynb 单元格 9\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/model_training_Transformer_self_supervise.ipynb#X10sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m batch_texts \u001b[39m=\u001b[39m d[\u001b[39m'\u001b[39m\u001b[39mph_seq_encoded\u001b[39m\u001b[39m'\u001b[39m][i:i \u001b[39m+\u001b[39m \u001b[39m32\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/model_training_Transformer_self_supervise.ipynb#X10sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# Tokenize the text batch\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/model_training_Transformer_self_supervise.ipynb#X10sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m encoding \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39;49mbatch_encode_plus(batch_texts, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/model_training_Transformer_self_supervise.ipynb#X10sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m                                     max_length\u001b[39m=\u001b[39;49mmax_sequence_length, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/model_training_Transformer_self_supervise.ipynb#X10sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m                                     padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmax_length\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/model_training_Transformer_self_supervise.ipynb#X10sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m                                     truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/model_training_Transformer_self_supervise.ipynb#X10sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m                                     return_tensors\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtf\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/model_training_Transformer_self_supervise.ipynb#X10sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39m# Extract input IDs and attention masks from the encoding\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/model_training_Transformer_self_supervise.ipynb#X10sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m input_ids \u001b[39m=\u001b[39m encoding[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Niko\\anaconda3\\envs\\ProjectVivy\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3075\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   3065\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   3066\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   3067\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[0;32m   3068\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3072\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   3073\u001b[0m )\n\u001b[1;32m-> 3075\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_encode_plus(\n\u001b[0;32m   3076\u001b[0m     batch_text_or_text_pairs\u001b[39m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   3077\u001b[0m     add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[0;32m   3078\u001b[0m     padding_strategy\u001b[39m=\u001b[39mpadding_strategy,\n\u001b[0;32m   3079\u001b[0m     truncation_strategy\u001b[39m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   3080\u001b[0m     max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[0;32m   3081\u001b[0m     stride\u001b[39m=\u001b[39mstride,\n\u001b[0;32m   3082\u001b[0m     is_split_into_words\u001b[39m=\u001b[39mis_split_into_words,\n\u001b[0;32m   3083\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   3084\u001b[0m     return_tensors\u001b[39m=\u001b[39mreturn_tensors,\n\u001b[0;32m   3085\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   3086\u001b[0m     return_attention_mask\u001b[39m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   3087\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   3088\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   3089\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   3090\u001b[0m     return_length\u001b[39m=\u001b[39mreturn_length,\n\u001b[0;32m   3091\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[0;32m   3092\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   3093\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Niko\\anaconda3\\envs\\ProjectVivy\\lib\\site-packages\\transformers\\tokenization_utils.py:801\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    799\u001b[0m     ids, pair_ids \u001b[39m=\u001b[39m ids_or_pair_ids, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    800\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 801\u001b[0m     ids, pair_ids \u001b[39m=\u001b[39m ids_or_pair_ids\n\u001b[0;32m    803\u001b[0m first_ids \u001b[39m=\u001b[39m get_input_ids(ids)\n\u001b[0;32m    804\u001b[0m second_ids \u001b[39m=\u001b[39m get_input_ids(pair_ids) \u001b[39mif\u001b[39;00m pair_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertModel, BertTokenizer\n",
    "from tqdm import tqdm  # for a progress bar\n",
    "\n",
    "# Load the data\n",
    "d = pd.read_csv(file_path)\n",
    "\n",
    "# Convert string representations of lists to actual lists\n",
    "d['ph_seq_encoded'] = d['ph_seq_encoded'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "# Initialize the BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define your input placeholders\n",
    "# Adjust these based on how you preprocess your data for BERT\n",
    "input_ids = tf.keras.Input(shape=(max_sequence_length,), dtype='int32', name=\"input_ids\")\n",
    "attention_mask = tf.keras.Input(shape=(max_sequence_length,), dtype='int32', name=\"attention_mask\")\n",
    "\n",
    "# Define the BERT model as part of your Keras model\n",
    "bert_output = bert_model(input_ids, attention_mask=attention_mask)[0]\n",
    "\n",
    "# Continue with your custom layers\n",
    "transformer_output = tf.keras.layers.Dense(64, activation='relu')(bert_output)\n",
    "\n",
    "# Output layers for each prediction\n",
    "ph_dur_output = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1, activation='linear'), name='ph_dur_output')(transformer_output)\n",
    "f0_seq_output = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1, activation='linear'), name='f0_seq_output')(transformer_output)\n",
    "note_output = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_notes), name='note_output')(transformer_output)\n",
    "\n",
    "# Compile the model\n",
    "model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=[ph_dur_output, f0_seq_output, note_output])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss={\n",
    "        'ph_dur_output': 'mean_squared_error',\n",
    "        'f0_seq_output': 'mean_squared_error',\n",
    "        'note_output': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    },\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Create a TensorFlow session\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    # Initialize all variables\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "    # Define the number of epochs for training\n",
    "    num_epochs = 10\n",
    "    # Your training loop here\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch:\", epoch)\n",
    "\n",
    "        # Shuffle your training data if necessary\n",
    "        # Example: X_train, y_ph_dur_train, y_f0_seq_train, y_notes_train = shuffle_data(X_train, y_ph_dur_train, y_f0_seq_train, y_notes_train)\n",
    "\n",
    "        # Iterate over batches of data\n",
    "        for i in tqdm(range(0, len(X_train), 32)):\n",
    "            # Extract batch of text data\n",
    "            batch_texts = d['ph_seq_encoded'][i:i + 32]\n",
    "\n",
    "            # Tokenize the text batch\n",
    "            encoding = tokenizer.batch_encode_plus(batch_texts, \n",
    "                                                max_length=max_sequence_length, \n",
    "                                                padding='max_length', \n",
    "                                                truncation=True,\n",
    "                                                return_tensors='tf')\n",
    "\n",
    "            # Extract input IDs and attention masks from the encoding\n",
    "            input_ids = encoding['input_ids']\n",
    "            attention_masks = encoding['attention_mask']\n",
    "\n",
    "            # Extract corresponding targets for the batch\n",
    "            batch_ph_dur = y_ph_dur_train[i:i + 32]\n",
    "            batch_f0_seq = y_f0_seq_train[i:i + 32]\n",
    "            batch_notes = y_notes_train[i:i + 32]\n",
    "\n",
    "            # Train on the batch\n",
    "            model.train_on_batch([input_ids, attention_masks], [batch_ph_dur, batch_f0_seq, batch_notes])\n",
    "    # Save the trained model\n",
    "    saver = tf.compat.v1.train.Saver()\n",
    "    saver.save(sess, 'model_transformer.ckpt')\n",
    "\n",
    "# import joblib\n",
    "\n",
    "# # Save the scalers and encoders\n",
    "# joblib.dump(scaler_ph_dur, 'scaler_ph_dur.pkl')\n",
    "# joblib.dump(scaler_f0_seq, 'scaler_f0_seq.pkl')\n",
    "# joblib.dump(encoder, 'ph_seq_encoder.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Validation\n",
    "Put user input and get output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the encoding dictionary from the ph_token_to_int.json file\n",
    "with open('ph_token_to_int.json', 'r') as file:\n",
    "    ph_token_to_int = json.load(file)\n",
    "\n",
    "# Your input sequence\n",
    "input_sequence = \"AP n ei f a g e n a j i f u y u a p u AP n ei f a g e n a l e y u d ao en AP\"\n",
    "\n",
    "# Split the input sequence into individual phonemes\n",
    "input_phonemes = input_sequence.split()\n",
    "\n",
    "# Convert the phonemes to their corresponding integers using the encoding dictionary\n",
    "encoded_sequence = [ph_token_to_int[phoneme] for phoneme in input_phonemes]\n",
    "\n",
    "# Convert the sequence to a numpy array and pad it to the right length\n",
    "new_ph_seq_encoded = np.array([encoded_sequence])  # wrapping in a list to create a batch dimension\n",
    "new_ph_seq_encoded_padded = pad_sequences(new_ph_seq_encoded, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "print(encoded_sequence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(user_input_padded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ph_dur, predicted_f0_seq, predicted_note_seq_encoded = predictions\n",
    "\n",
    "predicted_ph_dur_2d = predicted_ph_dur.reshape(-1, 1)\n",
    "\n",
    "# Apply inverse transformation\n",
    "decoded_ph_dur_2d = scaler_ph_dur.inverse_transform(predicted_ph_dur_2d)\n",
    "# print(predicted_ph_dur_2d)\n",
    "\n",
    "# Reshape it back to the original shape if needed\n",
    "decoded_ph_dur = decoded_ph_dur_2d.reshape(-1, max_sequence_length)\n",
    "\n",
    "\n",
    "\n",
    "predicted_f0_seq_2d = predicted_f0_seq.reshape(-1, 1)\n",
    "\n",
    "# Reverse normalization for 'f0_seq', if it's not all NaNs\n",
    "if not np.isnan(y_f0_seq_train).all():\n",
    "    decoded_f0_seq_2d = scaler_f0_seq.inverse_transform(predicted_f0_seq_2d)\n",
    "else:\n",
    "    decoded_f0_seq_2d = None  # or a placeholder value if f0_seq was not predicted\n",
    "    \n",
    "decoded_f0_seq = decoded_f0_seq_2d.reshape(-1, max_sequence_length)\n",
    "\n",
    "# Convert predicted probabilities for 'note_seq_encoded' back to category indices\n",
    "decoded_note_seq_encoded = np.argmax(predicted_note_seq_encoded, axis=-1)  # If the last dimension contains the category probabilities\n",
    "\n",
    "# If the decoded sequences are padded, you may want to trim the padding off. For example:\n",
    "trim_padding = lambda seq, mask: seq[:np.where(seq == mask)[0][0] if np.where(seq == mask)[0].size > 0 else None]\n",
    "# Now you can trim the padding if your original sequences were padded\n",
    "decoded_ph_dur_trimmed = [seq[seq != mask_value] for seq in decoded_ph_dur]\n",
    "if decoded_f0_seq is not None:\n",
    "    decoded_f0_seq_trimmed = [trim_padding(seq, mask_value) for seq in decoded_f0_seq]\n",
    "decoded_note_seq_encoded_trimmed = [trim_padding(seq, mask_value) for seq in decoded_note_seq_encoded]\n",
    "\n",
    "# Now you can print or return the decoded predictions\n",
    "print(\"Decoded ph_dur:\", decoded_ph_dur_trimmed)\n",
    "print(len(decoded_ph_dur_trimmed[0]))\n",
    "if decoded_f0_seq is not None:\n",
    "    print(\"Decoded f0_seq:\", decoded_f0_seq_trimmed)\n",
    "    print(len(decoded_f0_seq_trimmed[0]))\n",
    "print(\"Decoded note_seq_encoded:\", decoded_note_seq_encoded_trimmed)\n",
    "print(len(decoded_note_seq_encoded_trimmed[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Removing zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_timestep = 0.005\n",
    "f0_constant = 205.1\n",
    "def remove_trailing_zeros(sequence):\n",
    "    # Find the last non-zero element in the sequence\n",
    "    last_non_zero = -1\n",
    "    for i in range(len(sequence) - 1, -1, -1):\n",
    "        if sequence[i] != 0:\n",
    "            last_non_zero = i\n",
    "            break\n",
    "    # Slice the sequence to remove trailing zeros\n",
    "    return sequence[:last_non_zero + 1] if last_non_zero != -1 else sequence\n",
    "\n",
    "# Apply this function to each of your predicted sequences\n",
    "decoded_ph_dur_no_zeros = remove_trailing_zeros(decoded_ph_dur_trimmed[0])\n",
    "decoded_f0_seq_no_zeros = remove_trailing_zeros(decoded_f0_seq_trimmed[0])\n",
    "decoded_note_seq_encoded_no_zeros = remove_trailing_zeros(decoded_note_seq_encoded_trimmed[0])\n",
    "\n",
    "if len(decoded_ph_dur_no_zeros) > len(input_phonemes):\n",
    "        # Truncate the sequence if it's longer\n",
    "    decoded_ph_dur_no_zeros = decoded_ph_dur_no_zeros[:len(input_phonemes)]\n",
    "elif len(decoded_ph_dur_no_zeros) < len(input_phonemes):\n",
    "    # Pad the sequence with zeros if it's shorter\n",
    "    decoded_ph_dur_no_zeros = np.pad(decoded_ph_dur_no_zeros, (0, len(input_phonemes) - len(decoded_ph_dur_no_zeros)), 'constant')\n",
    "\n",
    "total_time = sum(decoded_ph_dur_no_zeros)\n",
    "\n",
    "print(total_time)\n",
    "f0_size = int(total_time / f0_timestep)\n",
    "print(f0_size)\n",
    "# Replace non-positive values with the specified constant\n",
    "decoded_f0_seq_no_zeros = [x if x > 0 else f0_constant for x in decoded_f0_seq_no_zeros]\n",
    "\n",
    "# Pad sequence with the constant value if it's shorter than the target length\n",
    "if len(decoded_f0_seq_no_zeros) < f0_size:\n",
    "    decoded_f0_seq_no_zeros = np.pad(decoded_f0_seq_no_zeros, (0, f0_size - len(decoded_f0_seq_no_zeros)), 'constant', constant_values=(f0_constant,))\n",
    "\n",
    "# Or truncate if it's longer than the target length (just for safety)\n",
    "elif len(decoded_f0_seq_no_zeros) > f0_size:\n",
    "    decoded_f0_seq_no_zeros = decoded_f0_seq_no_zeros[:f0_size]\n",
    "\n",
    "# Now you have your sequences with trailing zeros removed\n",
    "print(\"Decoded ph_dur without trailing zeros:\", decoded_ph_dur_no_zeros)\n",
    "print(len(decoded_ph_dur_no_zeros))\n",
    "if decoded_f0_seq_no_zeros is not None:\n",
    "    print(\"Decoded f0_seq without trailing zeros:\", decoded_f0_seq_no_zeros)\n",
    "    print(len(decoded_f0_seq_no_zeros))\n",
    "print(\"Decoded note_seq_encoded without trailing zeros:\", decoded_note_seq_encoded_no_zeros)\n",
    "print(len(decoded_note_seq_encoded_no_zeros))\n",
    "print(len(input_phonemes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Make it .ds file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use input_phonemes\n",
    "\n",
    "# Load the token-to-int mappings from the JSON files\n",
    "def load_mapping(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        token_to_int = json.load(f)\n",
    "    # Invert the dictionary to create an int-to-token mapping\n",
    "    int_to_token = {v: k for k, v in token_to_int.items()}\n",
    "    return int_to_token\n",
    "\n",
    "# Decoding function using the mappings\n",
    "def decode_predictions(prediction_integers, mapping):\n",
    "    return [mapping.get(i, 'Unknown') for i in prediction_integers]\n",
    "\n",
    "note_int_to_token = load_mapping('note_token_to_int.json')\n",
    "\n",
    "predicted_note_seq_integers = decoded_note_seq_encoded_no_zeros\n",
    "\n",
    "decoded_note_seq = decode_predictions(predicted_note_seq_integers, note_int_to_token)\n",
    "\n",
    "# Print or return the decoded sequences\n",
    "print(\"Decoded Phonetic Sequence:\", input_phonemes)\n",
    "print(\"Decoded Note Sequence:\", decoded_note_seq)\n",
    "\n",
    "file = {\n",
    "    'ph_seq': input_phonemes,\n",
    "    'ph_dur': decoded_ph_dur_no_zeros,\n",
    "    'note_seq': decoded_note_seq,\n",
    "    'f0_seq': decoded_f0_seq_no_zeros\n",
    "}\n",
    "\n",
    "with open('rnn_output.ds', 'w') as json_file:\n",
    "    json.dump(file, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjectVivy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
