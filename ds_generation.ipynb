{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate result (in .ds file) based on input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "model_addr = './models/model_rnn_gru.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Loading\n",
    "Load the model and scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Niko\\anaconda3\\envs\\ProjectVivy\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tensorflow.keras.models.load_model(model_addr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Lyric Input\n",
    "Make sure the lyric is been preprocessed in GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input sequence\n",
    "input_sequence = \"AP n ei f a g e n a j i f u y u a p u AP n ei f a g e n a l e y u d ao en AP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the encoding dictionary from the ph_token_to_int.json file\n",
    "with open('ph_token_to_int.json', 'r') as file:\n",
    "    ph_token_to_int = json.load(file)\n",
    "    \n",
    "# Split the input sequence into individual phonemes\n",
    "input_phonemes = input_sequence.split()\n",
    "\n",
    "# Convert the phonemes to their corresponding integers using the encoding dictionary\n",
    "encoded_sequence = [ph_token_to_int[phoneme] for phoneme in input_phonemes]\n",
    "\n",
    "# Convert the sequence to a numpy array and pad it to the right length\n",
    "ph_seq_encoded = np.array([encoded_sequence]) \n",
    "\n",
    "user_input = pad_sequences(ph_seq_encoded, maxlen=283, padding='post', truncating='post', dtype='float64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Inference\n",
    "Generate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_note_pred, y_dur_pred = model.predict(user_input)\n",
    "print(y_note_pred.shape, y_note_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Decoding\n",
    "Decode the prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the result\n",
    "input_length = len(encoded_sequence)\n",
    "y_note_pred = y_note_pred[:, :input_length, :]\n",
    "y_dur_pred = y_dur_pred[:, :input_length, :]\n",
    "\n",
    "# print(y_note_pred.shape, y_dur_pred.shape)\n",
    "\n",
    "# Load the saved scaler\n",
    "note_scaler = joblib.load('note_scaler.pkl')\n",
    "\n",
    "y_note_pred_flattened = y_note_pred.flatten()\n",
    "\n",
    "# Inverse transform the predictions\n",
    "y_note_pred_original = note_scaler.inverse_transform(y_note_pred_flattened.reshape(-1, 1))\n",
    "\n",
    "# Reshape back to the original shape if required\n",
    "y_note_pred_original = y_note_pred_original.reshape(y_note_pred.shape)\n",
    "y_note_pred_original = np.round(y_note_pred_original).astype(int)\n",
    "\n",
    "f0_timestep = 0.005\n",
    "f0_seq_constant = 250.1\n",
    "\n",
    "total_time = np.sum(y_dur_pred)\n",
    "print(total_time)\n",
    "f0_size = int(total_time / f0_timestep)\n",
    "# print(f0_size)\n",
    "\n",
    "f0_seq = [f0_seq_constant] * f0_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Output .ds file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_note_pred_flattened = y_note_pred_original[0]\n",
    "y_note_pred_output = [int(i) for i in y_note_pred_flattened]\n",
    "\n",
    "y_dur_pred_flattened = y_dur_pred[0]\n",
    "y_dur_pred_output = [float(i) for i in y_dur_pred_flattened]\n",
    "\n",
    "# Load the token-to-int mappings from the JSON files\n",
    "def load_mapping(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        token_to_int = json.load(f)\n",
    "    # Invert the dictionary to create an int-to-token mapping\n",
    "    int_to_token = {v: k for k, v in token_to_int.items()}\n",
    "    return int_to_token\n",
    "\n",
    "# Decoding function using the mappings\n",
    "def decode_predictions(prediction_integers, mapping):\n",
    "    return [mapping.get(i, 'Unknown') for i in prediction_integers]\n",
    "\n",
    "note_int_to_token = load_mapping('note_token_to_int.json')\n",
    "\n",
    "decoded_note_seq = decode_predictions(y_note_pred_output, note_int_to_token)\n",
    "\n",
    "# Print or return the decoded sequences\n",
    "# print(\"Decoded Phonetic Sequence:\", input_phonemes)\n",
    "# print(\"Decoded Note Sequence:\", decoded_note_seq)\n",
    "\n",
    "ph_dur = ' '.join(map(str, y_dur_pred_output))\n",
    "note_seq = ' '.join(map(str, decoded_note_seq))\n",
    "f0_seq = ' '.join(map(str, f0_seq))\n",
    "\n",
    "file = {\n",
    "    'ph_seq': input_sequence,\n",
    "    'ph_dur': ph_dur,\n",
    "    'note_seq': note_seq,\n",
    "    'f0_seq': f0_seq,\n",
    "    'f0_timestep': f0_timestep\n",
    "}\n",
    "\n",
    "with open('rnn_gru_output.ds', 'w') as json_file:\n",
    "    json.dump(file, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjectVivy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
