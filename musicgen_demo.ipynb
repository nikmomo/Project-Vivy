{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MusicGen\n",
    "Welcome to MusicGen's demo jupyter notebook. Here you will find a series of self-contained examples of how to use MusicGen in different settings.\n",
    "\n",
    "First, we start by initializing MusicGen, you can choose a model from the following selection:\n",
    "1. `facebook/musicgen-small` - 300M transformer decoder.\n",
    "2. `facebook/musicgen-medium` - 1.5B transformer decoder.\n",
    "3. `facebook/musicgen-melody` - 1.5B transformer decoder also supporting melody conditioning.\n",
    "4. `facebook/musicgen-large` - 3.3B transformer decoder.\n",
    "\n",
    "We will use the `facebook/musicgen-small` variant for the purpose of this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Niko\\Documents\\GitHub\\Song-Generation-Model-with-Vocal-Project-Vivy\\musicgen_demo.ipynb 单元格 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maudiocraft\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m MusicGen\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maudiocraft\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m MultiBandDiffusion\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m USE_DIFFUSION_DECODER \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Niko\\anaconda3\\envs\\ProjectVivy\\lib\\site-packages\\audiocraft\\__init__.py:24\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mAudioCraft is a general framework for training audio generative models.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mAt the moment we provide the training code for:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39m    improves the perceived quality and reduces the artifacts coming from adversarial decoders.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m# flake8: noqa\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m data, modules, models\n\u001b[0;32m     26\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m1.1.0\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Niko\\anaconda3\\envs\\ProjectVivy\\lib\\site-packages\\audiocraft\\data\\__init__.py:10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39m\"\"\"Audio loading and writing support. Datasets for raw audio\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mor also including some metadata.\"\"\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m# flake8: noqa\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m audio, audio_dataset, info_audio_dataset, music_dataset, sound_dataset\n",
      "File \u001b[1;32mc:\\Users\\Niko\\anaconda3\\envs\\ProjectVivy\\lib\\site-packages\\audiocraft\\data\\audio.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msoundfile\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mimport\u001b[39;00m functional \u001b[39mas\u001b[39;00m F\n\u001b[0;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mav\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from audiocraft.models import MusicGen\n",
    "from audiocraft.models import MultiBandDiffusion\n",
    "\n",
    "USE_DIFFUSION_DECODER = False\n",
    "# Using small model, better results would be obtained with `medium` or `large`.\n",
    "model = MusicGen.get_pretrained('facebook/musicgen-small')\n",
    "if USE_DIFFUSION_DECODER:\n",
    "    mbd = MultiBandDiffusion.get_mbd_musicgen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us configure the generation parameters. Specifically, you can control the following:\n",
    "* `use_sampling` (bool, optional): use sampling if True, else do argmax decoding. Defaults to True.\n",
    "* `top_k` (int, optional): top_k used for sampling. Defaults to 250.\n",
    "* `top_p` (float, optional): top_p used for sampling, when set to 0 top_k is used. Defaults to 0.0.\n",
    "* `temperature` (float, optional): softmax temperature parameter. Defaults to 1.0.\n",
    "* `duration` (float, optional): duration of the generated waveform. Defaults to 30.0.\n",
    "* `cfg_coef` (float, optional): coefficient used for classifier free guidance. Defaults to 3.0.\n",
    "\n",
    "When left unchanged, MusicGen will revert to its default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Niko\\Documents\\GitHub\\Song-Generation-Model-with-Vocal-Project-Vivy\\musicgen_demo.ipynb 单元格 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mset_generation_params(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     use_sampling\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     top_k\u001b[39m=\u001b[39m\u001b[39m250\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     duration\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.set_generation_params(\n",
    "    use_sampling=True,\n",
    "    top_k=250,\n",
    "    duration=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can go ahead and start generating music using one of the following modes:\n",
    "* Unconditional samples using `model.generate_unconditional`\n",
    "* Music continuation using `model.generate_continuation`\n",
    "* Text-conditional samples using `model.generate`\n",
    "* Melody-conditional samples using `model.generate_with_chroma`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Music Continuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torchaudio\n",
    "import torch\n",
    "from audiocraft.utils.notebook import display_audio\n",
    "\n",
    "def get_bip_bip(bip_duration=0.125, frequency=440,\n",
    "                duration=0.5, sample_rate=32000, device=\"cuda\"):\n",
    "    \"\"\"Generates a series of bip bip at the given frequency.\"\"\"\n",
    "    t = torch.arange(\n",
    "        int(duration * sample_rate), device=\"cuda\", dtype=torch.float) / sample_rate\n",
    "    wav = torch.cos(2 * math.pi * 440 * t)[None]\n",
    "    tp = (t % (2 * bip_duration)) / (2 * bip_duration)\n",
    "    envelope = (tp >= 0.5).float()\n",
    "    return wav * envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Niko\\Documents\\GitHub\\Song-Generation-Model-with-Vocal-Project-Vivy\\musicgen_demo.ipynb 单元格 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mIs CUDA enabled?\u001b[39m\u001b[39m\"\u001b[39m,torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Is CUDA enabled?\",torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Niko\\Documents\\GitHub\\Song-Generation-Model-with-Vocal-Project-Vivy\\musicgen_demo.ipynb 单元格 8\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Here we use a synthetic signal to prompt both the tonality and the BPM\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# of the generated audio.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m res \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mgenerate_continuation(\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     get_bip_bip(\u001b[39m0.125\u001b[39;49m)\u001b[39m.\u001b[39mexpand(\u001b[39m2\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m32000\u001b[39m, [\u001b[39m'\u001b[39m\u001b[39mJazz jazz and only jazz\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mHeartful EDM with beautiful synths and chords\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     progress\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m display_audio(res, \u001b[39m32000\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\Niko\\Documents\\GitHub\\Song-Generation-Model-with-Vocal-Project-Vivy\\musicgen_demo.ipynb 单元格 8\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_bip_bip\u001b[39m(bip_duration\u001b[39m=\u001b[39m\u001b[39m0.125\u001b[39m, frequency\u001b[39m=\u001b[39m\u001b[39m440\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                 duration\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, sample_rate\u001b[39m=\u001b[39m\u001b[39m32000\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Generates a series of bip bip at the given frequency.\"\"\"\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49marange(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39mint\u001b[39;49m(duration \u001b[39m*\u001b[39;49m sample_rate), device\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat) \u001b[39m/\u001b[39m sample_rate\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     wav \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcos(\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m math\u001b[39m.\u001b[39mpi \u001b[39m*\u001b[39m \u001b[39m440\u001b[39m \u001b[39m*\u001b[39m t)[\u001b[39mNone\u001b[39;00m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Niko/Documents/GitHub/Song-Generation-Model-with-Vocal-Project-Vivy/musicgen_demo.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     tp \u001b[39m=\u001b[39m (t \u001b[39m%\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m bip_duration)) \u001b[39m/\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m bip_duration)\n",
      "File \u001b[1;32mc:\\Users\\Niko\\anaconda3\\envs\\ProjectVivy\\lib\\site-packages\\torch\\cuda\\__init__.py:289\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    285\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m     )\n\u001b[0;32m    288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m\"\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    290\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    291\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    292\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# Here we use a synthetic signal to prompt both the tonality and the BPM\n",
    "# of the generated audio.\n",
    "res = model.generate_continuation(\n",
    "    get_bip_bip(0.125).expand(2, -1, -1), \n",
    "    32000, ['Jazz jazz and only jazz', \n",
    "            'Heartful EDM with beautiful synths and chords'], \n",
    "    progress=True)\n",
    "display_audio(res, 32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use any audio from a file. Make sure to trim the file if it is too long!\n",
    "prompt_waveform, prompt_sr = torchaudio.load(\"../assets/bach.mp3\")\n",
    "prompt_duration = 2\n",
    "prompt_waveform = prompt_waveform[..., :int(prompt_duration * prompt_sr)]\n",
    "output = model.generate_continuation(prompt_waveform, prompt_sample_rate=prompt_sr, progress=True, return_tokens=True)\n",
    "display_audio(output[0], sample_rate=32000)\n",
    "if USE_DIFFUSION_DECODER:\n",
    "    out_diffusion = mbd.tokens_to_wav(output[1])\n",
    "    display_audio(out_diffusion, sample_rate=32000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text-conditional Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiocraft.utils.notebook import display_audio\n",
    "\n",
    "output = model.generate(\n",
    "    descriptions=[\n",
    "        #'80s pop track with bassy drums and synth',\n",
    "        #'90s rock song with loud guitars and heavy drums',\n",
    "        #'Progressive rock drum and bass solo',\n",
    "        #'Punk Rock song with loud drum and power guitar',\n",
    "        #'Bluesy guitar instrumental with soulful licks and a driving rhythm section',\n",
    "        #'Jazz Funk song with slap bass and powerful saxophone',\n",
    "        'drum and bass beat with intense percussions'\n",
    "    ],\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "display_audio(output[0], sample_rate=32000)\n",
    "if USE_DIFFUSION_DECODER:\n",
    "    out_diffusion = mbd.tokens_to_wav(output[1])\n",
    "    display_audio(out_diffusion, sample_rate=32000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melody-conditional Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from audiocraft.utils.notebook import display_audio\n",
    "\n",
    "model = MusicGen.get_pretrained('facebook/musicgen-melody')\n",
    "model.set_generation_params(duration=8)\n",
    "\n",
    "melody_waveform, sr = torchaudio.load(\"../assets/bach.mp3\")\n",
    "melody_waveform = melody_waveform.unsqueeze(0).repeat(2, 1, 1)\n",
    "output = model.generate_with_chroma(\n",
    "    descriptions=[\n",
    "        '80s pop track with bassy drums and synth',\n",
    "        '90s rock song with loud guitars and heavy drums',\n",
    "    ],\n",
    "    melody_wavs=melody_waveform,\n",
    "    melody_sample_rate=sr,\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "display_audio(output[0], sample_rate=32000)\n",
    "if USE_DIFFUSION_DECODER:\n",
    "    out_diffusion = mbd.tokens_to_wav(output[1])\n",
    "    display_audio(out_diffusion, sample_rate=32000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "b02c911f9b3627d505ea4a19966a915ef21f28afb50dbf6b2115072d27c69103"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
